# 데이터 분석의 과정
1. 이해 및 프로젝트의 목표 설정
2. 데이터 수집
3. 데이터 탐색 및 전처리
4. 데이터 분석
5. 시각화 설계 및 구현
6. 결과 해석 및 인사이트 도출

# 데이터 전처리
- 데이터 변환
    - 로그 변환
    - 지수 변환
    - 세제곱 변환
    - 제곱 변환
- 결측치 처리
- 데이터 인코딩
    - 원-핫 인코딩
    - 라벨 인코딩
- 스케일링
    - Standard Scaler
    - Robust Scaler
    - Minmax Scaler
    - Log transformation

#  지도학습 알고리즘과 비지도학습 알고리즘, 강화학습
- 지도학습 알고리즘
    - 연속적인 값을 예측하는 `회귀`
        - 단순회귀분석(Simple Linear Regression)
        - 다중회귀분석(Multiple Linear Regression)
    - 이산적인 값을 예측하는 `분류`
        - Logistic Regression
        - Decision Tree (분류&회귀 모두 사용 가능)
        - Random Forest
        - K-nearest Neighbors (KNN)
        - SVM
        - Boosting (분류&회귀 모두 사용 가능)
    - 신경망 Neural Network (NN)
    - Deep Learning
    - Naive Bayes
    - CNN(Convolution Neural Network)
    - RNN 
    
- 비지도학습 알고리즘
    - 군집화(Clustering)
        - 계층적 군집분석(Hiarchical Clustering)
        - 비계층적 군집분석(K-means Clustering)
    - 차원 축소(Dimensionality Reduction) 
        - PCA(Principal Component Analysis) 
        - t-SNE(t-Distributed Stochastic Neighbor Embedding)
    - 연관 규칙 학습(Association Rule Learning)
        - 어프라이어리(Apriori)
        - 이클렛(Eclat)

- 강화학습 
    - 특정한 환경에서 최적의 결정을 내리기 위한 보상 시스템 기반 학습
    - ex) 알파고(최적의 결정인 action을 했을 때 reward를 주는 방식)



# 군집분석의 개요
- 어떤 개체나 대상들을 밀접한 유사성 또는 비유사성에 의하여 유사한 특성을 지닌 개체들을 몇 개의 군집으로 집단화하는 비지도학습법
- 각 군집의 특성, 군집간의 차이 등에 대한 탐색대상으로, 집단에 대한 심화된 이해가 목적
- 특이 군집의 발견, 결측값의 보정 등에도 사용될 수 있음.

- 군집의 조건
    - 동일 군집에 속한 개체끼리는 유사한 속성이 매우 많음.
    - 다른 군집에 속하는 개체끼리는 유사한 속성이 매우 적음.


# 계층적 군집분석(Hiarchical Clustering)
병합적 vs 분할적
- 병합적 : 개체 간의 거리가 가까운 개체끼리 차례로 묶어주는 방법으로 군집을 정의
- 분할적 : 개체 간의 거리가 먼 개체끼리 나누어 가는 방법으로 군집을 정의
계층적 군집분석에서는 병합적 방법이 주로 사용됨

## 개체 간 거리 및 군집 간 거리의 정의
- 개체 간 거리
    -  유클리디안 거리
    - 맨해튼 거리
    - 민코우스키 거리
- 군집 간 거리
    - 단일 연결법 : 두 군집 간의 거리 중 최솟값
    - 완전 연결법 : 두 군집 간의 거리 중 최댓값
    - 평균 연결법 : 두 군집 간의 거리들의 평균
    - 중심 연결법 : 두 군집의 중심들 사이의 거리
    - 와드 연결법 : K개 중 2개의 군집을 하나의 군집으로 묶었을 때 오차제곱합이 증가하는 정도를 두 군집 간의 거리로 정의

# 비계층적 군집분석(K-means Clustering)
## K-평균 군집분석의 개요

- 사전에 결정된 군집 수 k에 기초하여, 전체 데이터를 상대적으로 유사한 k개의 군집으로 구분

- 계층적 방식에 비하여 계산량이 적고, 대용량 데이터를 빠르게 처리함

- 사전에 적절한 군집 수 k에 대한 예상이 필요

- 초기에 군집 중심이 어디로 지정되는지에 따라 최종 결과가 영향을 많이 받음

- 잡음이나 이상치의 영향을 많이 받음


## K-평균 군집분석 알고리즘

- 개체를 k개의 초기 군집으로 나눈다.

- 각 군집의 중심을 계산한 뒤 모든 개체들을 각 군집의 중심에 가장 가까운 군집에 할당시킨다.

- 새로운 개체를 받아들이거나 잃은 군집의 중심을 다시 계산한다.

- 위 과정을 더 이상의 재배치가 생기지 않을 때까지 반복한다.

## K-평균 군집분석에서 적절한 군집 수의 결정

- 오차제곱합(SSE, sum of squared error)

    - 각 군집 내 개체들과 해당 군집 중심점과의 거리를 제곱한 값들의 합

    - 오차제곱합이 작을수록 군집 내 유사성이 높아 잘 응집된 것임

- 군집 수 k에 따른 SSE의 변화를 Elbow차트로 시각화한 뒤, SSE가 급격히 감소하다가 완만해지기 시작하는 시점의 k를 적정 군집수로 판단

- k수가 늘수록 SSE는 감소하지만 적은 수의 k로 설정하는 것이 효율적

## K-평균 군집분석 장단점
- 장점

    - 계층적 방식에 비해 계산량이 적음
    - 대용량 데이터를 빠르게 처리 가능
- 단점
    - 초기에 군집 중심이 어디로 지정되는지에 따라 최종 결과가 영향을 많이 받음

# 단순회귀분석(Simple Linear Regression)
- 회귀분석
    - 독립변수와 종속변수 간의 함수적인 관련성을 규명하기 위하여 어떤 수학적 모형을 가정하고, 이 모형을 측정된 자료로부터 통계적으로 추정하는 분석방법
    - 단순회귀 : 독립변수가 1개

    - 다중회귀 : 독립변수가 2개 이상

```
y = a + bx + e

x : 설명변수(=독립변수)

y : 반응변수(=종속변수)

e : 오차항
```

- 단순선형회귀모형의 모수 추정

    - 모형이 포함한 미지의 모수 a,b를 추정하기 위하여 각 독립변수 x에 대응하는 종속변수 y로 짝지어진 n개의 표본인 관측치(x,y)가 주어짐.

    - 최소제곱법

        - 단순회귀모형에서 자료점과 회귀선 간의 수직거리 제곱합이 최소가 되도록 a와 b를 추정하는 방법

​

- 단순선형회귀모형의 유의성 검정

    - 모형의 유의성 t검정

        - 독립변수 x가 종속변수Y를 설명하기에 유용한 변수인가에 대한 통계적 추론은 회귀변수 B에 대한 검정을 통해 파악할 수 있음

        - 귀무가설과 대립가설을 비교했을 때, p-value < a (유의수준), 귀무가설 기각&대립가설 채택

- 단순선형회귀모형의 적합도
    - Y의 변동성 분해
        - 제곱합 SST = SSR + SSE
        - (y의 변동) = (모형으로 설명되는 변동) + (모형으로 설명되지 않는 변동)
    - 모형의 적합성
        - 결정계수 R^2
            - R^2 = SSR/SST = 1-SSE/SST
            - 결정계수는 항상 0과 1 사이의 값을 짐
            - y의 변동 가운데 추정된 회귀모형으로 통해 설명되는 변동의 비중을 의미
            - 0에 가까울수록 추정된 모형의 설명력이 떨어짐, 1에 가까울수록 설명력 좋음.
            - R^2 은 두 변수 간의 상관계수 r의 제곱과 같음  

# 다중회귀분석(Multiple Linear Regression)
- 정의
    - 독립변수가 두 개 이상인 선형회귀

- 범주형 독립변수가 포함된 회귀모형
    - 범주형 독립변수를 회귀모형에 포함하기 위해서는 더미변수 기법을 사용
    - 더미변수는 0 또는 1의 값을 갖는 변수로 아래와 같이 정의됨
    - 더미변수의 개수 = 범주의 개수 - 1

- 다중회귀모형의 변수선택
    - 가능한 적은 수의 설명변수로 좋은 예측력을 가지는 모형을 찾고자 함
    - 변수선택법
        - 전진선택법
            - 절편만 있는 모델에 중요한 변수를 하나씩 추가하는 방식
            - 한 번 선택된 변수는 제거되지 않는 단점이 있음
        - 후진선택법
            - 모든 변수가 포함된 모델에서 가장 중요하지 않는 변수부터 하나씩 제거
            - 한 번 제거된 변수는 선택되지 않는 단점이 있음
        - 단계선택법
            - 절편만 포함된 모델에서 출발해 가장 중요한 변수부터 추가하고, 모델에 포함되어 있는 변수 중에서 중요하지 않는 변수를 제거함
            - 더 이상 새롭게 추가되는 변수가 없을 때까지 변수의 추가 또는 삭제를 반복함
        - 모든 가능한 조합의 회귀분석 : 모든 독립변수들의 조합에 대해 회귀모형을 생성한 뒤 가장 적합한 회귀모형을 선택

- 모형 선택의 기준
    - 수정된 결정계수 (Adjusted R^2)
        - 결정계수R^2 는 새로운 독립변수가 추가되면 항상 증가함
        - 이를 보완한 수정결정계수는 추가된 독립변수가 종속변수를 설명하는데 기여하는 바가 큰 경우에만 증가함

- 가정 위반 검토 및 해결    
    - 잔차분석
        - 회귀 모형에서의 가정이 적절한 것인가에 대한 평가
        - 1: 오차의 정규성
        - 2: 오차의 등분산성
        - 3: 오차의 독립성
    - 검정을 통한 방법과 그래프를 통한 시각적인 확인 방법이 가능
        - 1: 오차의 정규성 위반 : 히스토그램, QQ플랫
        - 2: 오차의 등분산성 : 잔차산점도
        - 3: 오차의 독립성 : 잔차산점도
- 가정 위반 시 해결방안
    - 1: 오차의 정규성 위반 : 변수변환
    - 2: 오차의 등분산성 : 가중최소제곱회귀
    - 3: 오차의 독립성 : 시계열 분석

- 다중공선성 진단 및 해결
    - 다중공선성
        - 독립변수들 간에 강한 선형관계가 존재하는 경우 다중회귀모형 분석 시 자주 발생하는 문제 중 하나로 독립 변수 사이에 상관성이 있는 성질을 의미한다  
        - 다중회귀모형에서 회귀계수 추정에 부정적인 영향을 미침
        - 개별적인 회귀계수 추정의 신뢰성이 떨어져 추정치를 믿을 수 없게 만듦
        - 전반적인 모형의 적합성이나 정확도는 크게 변하지 않음
    - 다중공선성 진단방법
        ```
        VIF 계수 = 1/ 1-R^2
        ```
        VIF 계수가 5 또는 10 이상인 경우 다중공선성이 심각한 것으로 봄
    - 다중공선성 해결책
        - 변수선택으로 중북된 변수를 제거
        - 주성분 분석 등을 이용하여 중복된 변수를 변환하여 새로운 변수 생성
        - 릿지, 라쏘 등으로 중복된 변수의 영향력을 일부만 사용

# 규제가 있는 선형회귀모델 - 라쏘(Lasso Regression), 릿지(Ridge Regression), 엘라스틱넷(Elastic Net)

- 모델에 규제를 하는 이유

    - 모형의 과대적합을 막기 위한 규제바법으로 선형회귀모형에서는 보통 모델의 `가중치를 제한`하는 방법을 사용함
    - 추정량의 분산을 떨어뜨려 편향은 늘어나지만 변동성은 줄어든다
    - 이를 통해 모형의 복잡도를 낮출 수 있다

- 선형회귀모델의 규제
    - 라쏘회귀 (Lasso Regression)
    - 릿지회귀 (Ridge Regression)
    - 엘라스틱넷 (Elastic Net)

## 라쏘회귀 (Lasso Regression)와 L1 규제 
    - 불필요한 변수의 계수를 0으로 만들 수 있음. 이는 `특징 선택(feature selection)`으로 이어지며, 모델이 더 단순하고 해석하기 쉬워짐.
    - 변수 중 일부만이 중요하고, 다른 변수들은 거의 중요하지 않을 때 유용
    - 결과적으로 변수의 수를 줄이면서, `중요한 변수만을 남김`

## 릿지회귀 (Ridge Regression)와 L2 규제

    - 변수들의 영향력을 줄이되, 완전히 제거하지는 않음. 이는 모든 변수가 어느 정도의 정보를 제공한다고 가정함
    - 변수들 사이에 상관관계가 있거나, 데이터에 다중공선성 문제가 있을 때 유용
    - 결과적으로 `모든 변수를 보존`하면서, `각 변수의 영향력을 조절`

## 엘라스틱넷 (Elastic Net)

    - L1과 L2 규제를 혼합한 방식, 수행시간이 오래 걸림
    - 엘라스틱넷의 규제는 aL1 + bL2로 정의할 수 있으며, a와 b는 각각 L1, L2 규제의 alpha값이다.

​